<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="machine learning,deep learning,interview question,">





  <link rel="alternate" href="/atom.xml" title="Bluesliuf" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/apple-touch-icon-next.ico?v=5.1.0">






<meta name="description" content="最近忙着找实习，对计算机视觉中常见的问题做了简单梳理，会不定时更新。">
<meta name="keywords" content="machine learning,deep learning,interview question">
<meta property="og:type" content="article">
<meta property="og:title" content="计算机视觉常见问题（含解答）">
<meta property="og:url" content="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/index.html">
<meta property="og:site_name" content="Bluesliuf">
<meta property="og:description" content="最近忙着找实习，对计算机视觉中常见的问题做了简单梳理，会不定时更新。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/1.png">
<meta property="og:image" content="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/2.png">
<meta property="og:image" content="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/3.jpg">
<meta property="og:image" content="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/4.jpg">
<meta property="og:image" content="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/5.png">
<meta property="og:image" content="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/6.png">
<meta property="og:updated_time" content="2019-04-18T13:56:28.811Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="计算机视觉常见问题（含解答）">
<meta name="twitter:description" content="最近忙着找实习，对计算机视觉中常见的问题做了简单梳理，会不定时更新。">
<meta name="twitter:image" content="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":true,"scrollpercent":true},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/">





  <title> 计算机视觉常见问题（含解答） | Bluesliuf </title>
</head>


<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <link rel="stylesheet" href="/dist/APlayer.min.css">
  <div id="aplayer"></div>
  <script type="text/javascript" src="/dist/APlayer.min.js"></script>
  <script type="text/javascript" src="/dist/music.js"></script>
  
  
   <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  

  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?4287ae00cf6dc3cd776333fe30decd6a";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Bluesliuf</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Though failed, Still keep smiling</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            个人简历
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="bluesliuf">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Bluesliuf">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                计算机视觉常见问题（含解答）
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-18T21:03:07+08:00">
                2019-04-18
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-04-18T21:56:28+08:00">
                2019-04-18
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读次数
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          
            <div class="post-wordcount">
              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  4.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  15
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>最近忙着找实习，对计算机视觉中常见的问题做了简单梳理，会不定时更新。<a id="more"></a></p>
<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><h3 id="CNN在图像上表现好的原因"><a href="#CNN在图像上表现好的原因" class="headerlink" title="CNN在图像上表现好的原因"></a>CNN在图像上表现好的原因</h3><p>直接将图像数据作为输入，不仅<strong>无需人工对图像进行预处理和额外的特征抽取等复杂操作</strong>，而且以其特有的细粒度特征提取方式，使得对图像的处理达到了几近人力的水平。</p>
<h3 id="参数和计算量的计算"><a href="#参数和计算量的计算" class="headerlink" title="参数和计算量的计算"></a>参数和计算量的计算</h3><p>卷积输入为$Ｗ \times Ｈ \times Ｃ$，卷积核$K \times K \times Ｎ$，输出$Ｗ<em>{1} \times Ｈ</em>{1} \times Ｃ_{1}$</p>
<ol>
<li>计算量： $Ｗ<em>{1} \times Ｈ</em>{1} \times Ｃ_{1} \times K \times K \times C​$</li>
<li>参数量：$C_{1} \times K \times K \times C​$</li>
</ol>
<h3 id="调试、修改模型的经验"><a href="#调试、修改模型的经验" class="headerlink" title="调试、修改模型的经验"></a>调试、修改模型的经验</h3><ol>
<li><p><strong>数据层面</strong><br>获取更多的数据、数据扩增或生成、对数据进行归一化或者标准化、重新进行特征选择</p>
</li>
<li><p><strong>算法层面</strong></p>
<blockquote>
<p><strong>对算法进行抽样调查</strong>。选取性能最好的算法，然后通过进一步的调参和数据准备来提升。<br><strong>重采样方法</strong>。可以先在小数据集上完成模型选择和参数调优，然后再将最终的方法扩展到全部数据集上。</p>
</blockquote>
</li>
<li><p><strong>调参</strong></p>
<blockquote>
<p><strong>诊断</strong>。在每个周期， 评估模型在训练集和验证集上的表现， 并作出图表；<br><strong>权重初始化</strong>。尝试所有不同的初始化方法，考察是否有一种方法在其他情况不变的情况下(效果)更优；<br><strong>学习率</strong>。尝试随周期递减的学习率或增加动量项；<br><strong>激活函数</strong>。尝试常见的激活函数，并且重缩放你的数据以满足激活函数的边界；<br><strong>Batch size和周期</strong>。尝试不同的批次 batch size 和周期数，batch size 大小会决定最后的梯度， 以及更新权重的频度。<br><strong>正则化</strong>。尝试不同的正则化方式，权重衰减（Weight decay） 去惩罚大的权重、激活约束（Activation constraint） 去惩罚大的激活值、分别在输入， 隐藏层和输出层中试验 dropout 方法或者使用L1、L2正则化。<br><strong>优化算法和损失函数</strong>。尝试不同的优化算法（SGD、ADAM、RMSprop、、、）。要被优化的损失函数与你要解决的问题高度相关，也得适当调整。<br><strong>Early Stopping/早停法</strong>。一旦训练过程中出现(验证集)性能开始下降， 你可以停止训练与学习，是避免模型在训练数据上的过拟合的正则化方式。</p>
</blockquote>
</li>
<li><p><strong>通过嵌套模型提升性能</strong><br>通过组合多个“足够好的”模型来得到优秀的预测能力， 而不是通过组合多个高度调参的（脆弱的）模型。</p>
</li>
</ol>
<h3 id="简述-Inception-v1-v4区别、改进"><a href="#简述-Inception-v1-v4区别、改进" class="headerlink" title="简述 Inception v1-v4区别、改进"></a>简述 Inception v1-v4区别、改进</h3><h4 id="V1"><a href="#V1" class="headerlink" title="V1"></a>V1</h4><ol>
<li>采用<strong>不同大小的卷积核</strong>意味着不同大小的感受野，最后拼接意味着<strong>不同尺度特征的融合</strong>；</li>
<li>将CNN中常用的卷积（1x1，3x3，5x5）、池化操作（3x3）堆叠在一起（卷积、池化后的尺寸相同，将通道相加），一方面<strong>增加了网络的宽度，另一方面也增加了网络对尺度的适应性</strong>；</li>
<li>为了减少计算量，增加了1x1卷积。</li>
</ol>
<h4 id="V2"><a href="#V2" class="headerlink" title="V2"></a>V2</h4><ol>
<li>卷积分解，<strong>将单个的5x5卷积层用2个连续的3x3卷积层</strong>组成的小网络来代替，在保持感受野范围的同时又减少了参数量，也加深了网络。</li>
<li>提出了著名的<strong>Batch Normalization (BN)</strong>方法。BN会对每一个mini-batch数据的内部进行标准化（normalization）,使输出规范到N（0，1）的正态分布，加快了网络的训练速度,还可以增大学习率。</li>
<li>BN某种意义上起到了<strong>正则化的作用，所以可以减少或者取消dropout，简化网络结构</strong>。V2在训练达到V1准确率时快了14倍，最后收敛的准确率也比V1高。</li>
</ol>
<h4 id="V3"><a href="#V3" class="headerlink" title="V3"></a>V3</h4><ol>
<li>考虑了<strong>nx1卷积核</strong>，将一个较大的二维卷积拆成两个较小的一维卷积（7x7拆成了7x1和1x7，3x3拆成了1x3和3x1），一方面节约了大量参数，加速运算并减轻了过拟合），同时网络深度进一步增加，增加了网络的非线性。</li>
<li>优化了Inception Module的结构。</li>
</ol>
<h4 id="V4"><a href="#V4" class="headerlink" title="V4"></a>V4</h4><p>利用残差连接（Residual Connection）来改进V3结构。</p>
<h3 id="Inception-v1中的inception结构怎么设计的"><a href="#Inception-v1中的inception结构怎么设计的" class="headerlink" title="Inception v1中的inception结构怎么设计的"></a>Inception v1中的inception结构怎么设计的</h3><ol>
<li>采用<strong>不同大小的卷积核</strong>意味着不同大小的感受野，最后拼接意味着<strong>不同尺度特征的融合</strong>；</li>
<li>该结构将CNN中常用的卷积（1x1，3x3，5x5）、池化操作（3x3）堆叠在一起（卷积、池化后的尺寸相同，将通道相加），一方面<strong>增加了网络的宽度，另一方面也增加了网络对尺度的适应性</strong>。</li>
</ol>
<p><img src="/深度学习/2019-4-18-计算机视觉常见问题/1.png" alt=""></p>
<p>然而上面这个Inception原始版本，所有的卷积核都在上一层的所有输出上来做，而那个<strong>5x5的卷积核所需的计算量就太大了，约需要1.2亿次的计算量</strong>，造成了特征图的厚度很大。</p>
<ol start="3">
<li>为了避免这种情况，<strong>在3x3前、5x5前、max pooling后分别加上了1x1的卷积核，以起到了降低特征图厚度的作用</strong>，这也就形成了Inception v1的网络结构，如下图所示：</li>
</ol>
<p><img src="/深度学习/2019-4-18-计算机视觉常见问题/2.png" alt=""></p>
<h3 id="为什么使用1x1卷积核"><a href="#为什么使用1x1卷积核" class="headerlink" title="为什么使用1x1卷积核"></a>为什么使用1x1卷积核</h3><ol>
<li><strong>1x1卷积的主要目的是为了减少维度，还用于修正线性激活（ReLU）</strong>。比如上一层的输出为100x100x128，经过具有256个通道的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256，其中，卷积层的参数为<strong>128x5x5x256= 819200</strong>。而假如上一层输出先经过具有32个通道的1x1卷积层，再经过具有256个输出的5x5卷积层，那么输出数据仍为为100x100x256，但卷积参数量已经减少为<strong>128x1x1x32 + 32x5x5x256= 204800</strong>，大约减少了4倍。</li>
<li><strong>加深了网络的层次，同时也增强了网络的非线性</strong>。</li>
</ol>
<h3 id="简述-CNN-的演变"><a href="#简述-CNN-的演变" class="headerlink" title="简述 CNN 的演变"></a>简述 CNN 的演变</h3><ol>
<li><strong>LeNet</strong>：2个卷积3个全连接，最早用于数字识别</li>
<li><strong>AlexNet</strong>：12年ImageNet冠军，5个卷积3个全连接，多个小卷积代替单一大卷积；使用ReLU激活函数，解决梯度小数问题；引入dropout避免模型过拟合；最大池化。</li>
<li><strong>ZF-Net</strong>：13年ImageNet冠军，只用了一块 GPU 的稠密连接结构；将AlexNet第一层卷积核由11变成7，步长由4变为2。</li>
<li><strong>VGG-Nets</strong>：14年ImageNet分类第二名，更深的网络，卷积层使用更小的filter尺寸和间隔；多个小卷积让网络有更多的非线性，更少的参数。</li>
<li><strong>GoogLeNet</strong>：14年ImageNet分类第一名。引入Inception模块，采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合；采用了average pooling来代替全连接层；避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度。</li>
<li><strong>ResNet</strong>：引入残差单元，简化学习目标和难度，加快训练速度，模型加深时，不会产生退化问题；能够有效解决训练过程中梯度消失和梯度爆炸问题。</li>
<li><strong>DenseNet</strong>：密集连接；加强特征传播，鼓励特征复用，极大的减少了参数量。</li>
</ol>
<h3 id="讲一下CNN，每个层，及作用"><a href="#讲一下CNN，每个层，及作用" class="headerlink" title="讲一下CNN，每个层，及作用"></a>讲一下CNN，每个层，及作用</h3><p>CNN的特征检测层通过训练数据进行学习</p>
<ol>
<li>所以在使用CNN时，<strong>避免了显示的特征抽取，而隐式地从训练数据中进行学习</strong>；</li>
<li>由于<strong>同一特征映射面上的神经元权值相同</strong>，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的一大优势。</li>
<li>卷积神经网络以其<strong>局部权值共享</strong>的特殊结构在语音识别和图像处理方面有着独特的优越性。权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点<strong>避免了特征提取和分类过程中数据重建的复杂度</strong>。</li>
</ol>
<p>卷积神经网络（CNN）主要由卷积层、激活函数、池化层、全连接层组成。</p>
<ol>
<li><strong>卷积层（Conv）</strong>：使用卷积核进行特征提取和特征映射</li>
<li><strong>激活函数（Activation）</strong>：由于卷积也是一种线性运算，因此需要增加非线性映射</li>
<li><strong>池化层（Pool）</strong>：对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征</li>
<li><strong>全连接层（FC）</strong>：连接所有的特征，将输出值送给分类器</li>
</ol>
<h3 id="Pooling层怎么反向传播"><a href="#Pooling层怎么反向传播" class="headerlink" title="Pooling层怎么反向传播"></a>Pooling层怎么反向传播</h3><p>CNN网络中另外一个不可导的环节就是Pooling池化操作，因为Pooling操作使得feature map的尺寸变化，假如做2×2的池化（步长也为2），假设那么第l+1层的feature map有16个梯度，那么第l层就会有64个梯度，这使得梯度无法对位的进行传播下去。其实解决这个问题的思想也很简单，就是把1个像素的梯度传递给4个像素，但是<font color="#FF0000">需要保证传递的loss（或者梯度）总和不变</font>。根据这条原则，mean pooling和max pooling的反向传播也是不同的</p>
<ol>
<li><strong>mean pooling</strong><br>mean pooling的前向传播就是把一个patch中的值求取平均来做pooling，那么反向传播的过程也就是把<strong>某个元素的梯度等分为n份分配给前一层，这样就保证池化前后的梯度（残差）之和保持不变</strong>，图示如下 ：</li>
</ol>
<p><img src="/深度学习/2019-4-18-计算机视觉常见问题/3.jpg" alt=""></p>
<ol start="2">
<li><strong>max pooling</strong><br><strong>max pooling也要满足梯度之和不变的原则</strong>，max pooling的前向传播是把patch中最大的值传递给后一层，而其他像素的值直接被舍弃掉。那么<strong>反向传播也就是把梯度直接传给前一层某一个像素，而其他像素不接受梯度，也就是为0</strong>。所以max pooling操作和mean pooling操作不同点在于需要记录下池化操作时到底哪个像素的值是最大，也就是max id，这个变量就是记录最大值所在位置的，因为在反向传播中要用到，那么假设前向传播和反向传播的过程就如下图所示 ：</li>
</ol>
<p><img src="/深度学习/2019-4-18-计算机视觉常见问题/4.jpg" alt=""></p>
<h3 id="解释-ResNet-流行的原因"><a href="#解释-ResNet-流行的原因" class="headerlink" title="解释 ResNet 流行的原因"></a>解释 ResNet 流行的原因</h3><p><img src="/深度学习/2019-4-18-计算机视觉常见问题/5.png" alt=""></p>
<p>从上面两个图可以看出，在网络很深的时候（56层相比20层），模型效果却越来越差了（误差率越高），并不是网络越深越好。<br>ResNet创造性的引入了残差单元，很好的解决了这个问题。</p>
<ol>
<li>引入残差单元，简化学习目标和难度，加快训练速度，<strong>模型加深时，不会产生退化问题</strong></li>
<li>引入残差单元，能够有效<strong>解决训练过程中梯度消失和梯度爆炸问题</strong></li>
</ol>
<h3 id="Resnet第二个版本做了哪些改进"><a href="#Resnet第二个版本做了哪些改进" class="headerlink" title="Resnet第二个版本做了哪些改进"></a>Resnet第二个版本做了哪些改进</h3><p><img src="/深度学习/2019-4-18-计算机视觉常见问题/6.png" alt=""></p>
<p>ResNet_v2与v1的最大区别就是<strong>v2的BN和ReLU是在卷积之前使用的</strong>，好处：</p>
<ol>
<li>反向传播基本符合假设，信息传递无阻碍；</li>
<li>BN层作为pre-activation，起到了正则化的作用；</li>
</ol>
<h3 id="mobileNet、shuffleNet知道吗？"><a href="#mobileNet、shuffleNet知道吗？" class="headerlink" title="mobileNet、shuffleNet知道吗？"></a>mobileNet、shuffleNet知道吗？</h3><ol>
<li><p><strong>MobileNe</strong>t是为移动和嵌入式设备提出的高效模型。MobileNets基于流线型架构(streamlined)，使用<strong>深度可分离卷积</strong>(即Xception变体结构)来构建轻量级深度神经网络。<strong>宽度因子α用于控制输入和输出的通道数，分辨率因子ρ控制输入的分辨率</strong>。<br>例如，对于深度分离卷积，把标准卷积(4,4,3,5)分解为：</p>
<blockquote>
<p><strong>深度卷积部分</strong>：大小为(4,4,1,3)，作用在输入的每个通道上，输出特征映射为(3,3,3)<br><strong>逐点卷积部分</strong>：大小为(1,1,3,5)，作用在深度卷积的输出特征映射上，得到最终输出为(3,3,5)</p>
</blockquote>
</li>
<li><p><strong>shuffleNet</strong>专门应用于计算力受限的移动设备，主要包含2个操作：<strong>逐点群卷积（降低计算复杂度）和通道混洗（帮助信息流通）</strong>。</p>
</li>
</ol>
<h3 id="讲一下pooling的作用，-为什么max-pooling要更常用？哪些情况下，average-pooling比max-pooling更合适？"><a href="#讲一下pooling的作用，-为什么max-pooling要更常用？哪些情况下，average-pooling比max-pooling更合适？" class="headerlink" title="讲一下pooling的作用， 为什么max pooling要更常用？哪些情况下，average pooling比max pooling更合适？"></a>讲一下pooling的作用， 为什么max pooling要更常用？哪些情况下，average pooling比max pooling更合适？</h3><ol>
<li><strong>作用</strong>：对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征。</li>
<li>通常来讲，max-pooling的效果更好，虽然max-pooling和average-pooling都对数据做了下采样，但是<strong>max-pooling感觉更像是做了特征选择，选出了分类辨识度更好的特征，提供了非线性</strong>。 pooling的主要作用一方面是去掉冗余信息，一方面要保留feature map的特征信息，在分类问题中，我们需要知道的是这张图像有什么object，而不大关心这个object位置在哪，在这种情况下显然max pooling比average pooling更合适。在<strong>网络比较深的地方，特征已经稀疏了，从一块区域里选出最大的，比起这片区域的平均值来，更能把稀疏的特征传递下去</strong>。</li>
<li>average-pooling更强调对整体特征信息进行一层下采样，在减少参数维度的贡献上更大一点，更多的体现在<strong>信息的完整传递这个维度</strong>上，在一个很大很有代表性的模型中，比如说DenseNet中的模块之间的连接大多采用average-pooling，在减少维度的同时，更有利信息传递到下一个模块进行特征提取。<br>average-pooling在<strong>全局平均池化操作</strong>中应用也比较广，在ResNet和Inception结构中最后一层都使用了平均池化。有的时候在模型接近<strong>分类器的末端使用全局平均池化还可以代替Flatten操作</strong>，使输入数据变成一位向量。</li>
</ol>
<h3 id="哪些领域（数据集）不能使用深度学习？"><a href="#哪些领域（数据集）不能使用深度学习？" class="headerlink" title="哪些领域（数据集）不能使用深度学习？"></a>哪些领域（数据集）不能使用深度学习？</h3><ol>
<li><strong>数据集太小</strong>，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势</li>
<li><strong>数据集没有局部相关特性</strong>，目前深度学习表现比较好的领域主要是图像／语音／自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算法进行处理。举个例子：预测一个人的健康状况，相关的参数会有年龄、职业、收入、家庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。</li>
</ol>
<h3 id="细粒度分类"><a href="#细粒度分类" class="headerlink" title="细粒度分类"></a>细粒度分类</h3><h2 id="LSTM-amp-RNN"><a href="#LSTM-amp-RNN" class="headerlink" title="LSTM&amp;RNN"></a>LSTM&amp;RNN</h2><h3 id="解释LSTM结构（相对于RNN）的好处"><a href="#解释LSTM结构（相对于RNN）的好处" class="headerlink" title="解释LSTM结构（相对于RNN）的好处"></a>解释LSTM结构（相对于RNN）的好处</h3><h3 id="RNN的梯度消失原因和解决办法"><a href="#RNN的梯度消失原因和解决办法" class="headerlink" title="RNN的梯度消失原因和解决办法"></a>RNN的梯度消失原因和解决办法</h3><h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h2><h3 id="Unet的介绍"><a href="#Unet的介绍" class="headerlink" title="Unet的介绍"></a>Unet的介绍</h3><h3 id="FCN和Unet的区别"><a href="#FCN和Unet的区别" class="headerlink" title="FCN和Unet的区别"></a>FCN和Unet的区别</h3><h3 id="RCNN系列的算法流程和区别"><a href="#RCNN系列的算法流程和区别" class="headerlink" title="RCNN系列的算法流程和区别"></a>RCNN系列的算法流程和区别</h3><h3 id="Fast-RCNN中-bbox-回归的损失函数什么"><a href="#Fast-RCNN中-bbox-回归的损失函数什么" class="headerlink" title="Fast RCNN中 bbox 回归的损失函数什么"></a>Fast RCNN中 bbox 回归的损失函数什么</h3><h3 id="解释-ROI-Pooling-和-ROI-Align"><a href="#解释-ROI-Pooling-和-ROI-Align" class="headerlink" title="解释 ROI Pooling 和 ROI Align"></a>解释 ROI Pooling 和 ROI Align</h3><h3 id="Mask-RCNN中-mask-branch-如何接入-Faster-RCNN中"><a href="#Mask-RCNN中-mask-branch-如何接入-Faster-RCNN中" class="headerlink" title="Mask RCNN中 mask branch 如何接入 Faster RCNN中"></a>Mask RCNN中 mask branch 如何接入 Faster RCNN中</h3><h3 id="解释-FPN"><a href="#解释-FPN" class="headerlink" title="解释 FPN"></a>解释 FPN</h3><h3 id="解释-ROI-Align"><a href="#解释-ROI-Align" class="headerlink" title="解释 ROI Align"></a>解释 ROI Align</h3><h3 id="简述-YOLO-和-SSD"><a href="#简述-YOLO-和-SSD" class="headerlink" title="简述 YOLO 和 SSD"></a>简述 YOLO 和 SSD</h3><h3 id="简述-Hough-直线检测、Sobel-边缘检测算法流程"><a href="#简述-Hough-直线检测、Sobel-边缘检测算法流程" class="headerlink" title="简述 Hough 直线检测、Sobel 边缘检测算法流程"></a>简述 Hough 直线检测、Sobel 边缘检测算法流程</h3><h3 id="Mask-RCNN中的anchors如何判定为正负样本"><a href="#Mask-RCNN中的anchors如何判定为正负样本" class="headerlink" title="Mask RCNN中的anchors如何判定为正负样本"></a>Mask RCNN中的anchors如何判定为正负样本</h3><h3 id="简述-NMS-算法流程"><a href="#简述-NMS-算法流程" class="headerlink" title="简述 NMS 算法流程"></a>简述 NMS 算法流程</h3><h3 id="attention起源是用在哪里？pixel还是frame，是soft还是hard"><a href="#attention起源是用在哪里？pixel还是frame，是soft还是hard" class="headerlink" title="attention起源是用在哪里？pixel还是frame，是soft还是hard"></a>attention起源是用在哪里？pixel还是frame，是soft还是hard</h3><h3 id="anchor的正负样本比是多少"><a href="#anchor的正负样本比是多少" class="headerlink" title="anchor的正负样本比是多少"></a>anchor的正负样本比是多少</h3><h2 id="算法和激活函数等"><a href="#算法和激活函数等" class="headerlink" title="算法和激活函数等"></a>算法和激活函数等</h2><h3 id="BN的原理和作用"><a href="#BN的原理和作用" class="headerlink" title="BN的原理和作用"></a>BN的原理和作用</h3><p>###BN层反向传播，怎么求导</p>
<h3 id="BN-的作用和缺陷，以及针对batch-size小的情况的改进（GN）"><a href="#BN-的作用和缺陷，以及针对batch-size小的情况的改进（GN）" class="headerlink" title="BN 的作用和缺陷，以及针对batch_size小的情况的改进（GN）"></a>BN 的作用和缺陷，以及针对batch_size小的情况的改进（GN）</h3><h3 id="BN层，先加BN还是激活，有什么区别"><a href="#BN层，先加BN还是激活，有什么区别" class="headerlink" title="BN层，先加BN还是激活，有什么区别"></a>BN层，先加BN还是激活，有什么区别</h3><h3 id="手推BP"><a href="#手推BP" class="headerlink" title="手推BP"></a>手推BP</h3><h3 id="优化算法举例和他们的区别（SGD、SGDM、RMSprop、Adam）"><a href="#优化算法举例和他们的区别（SGD、SGDM、RMSprop、Adam）" class="headerlink" title="优化算法举例和他们的区别（SGD、SGDM、RMSprop、Adam）"></a>优化算法举例和他们的区别（SGD、SGDM、RMSprop、Adam）</h3><h3 id="随机梯度下降和梯度下降"><a href="#随机梯度下降和梯度下降" class="headerlink" title="随机梯度下降和梯度下降"></a>随机梯度下降和梯度下降</h3><h3 id="训练不收敛的原因有哪些"><a href="#训练不收敛的原因有哪些" class="headerlink" title="训练不收敛的原因有哪些"></a>训练不收敛的原因有哪些</h3><h3 id="简述-SVM-流程、核函数寻参及常见的核函数举例"><a href="#简述-SVM-流程、核函数寻参及常见的核函数举例" class="headerlink" title="简述 SVM 流程、核函数寻参及常见的核函数举例"></a>简述 SVM 流程、核函数寻参及常见的核函数举例</h3><h3 id="batch-size-和-learning-rate-的关系（怎么平衡和调整二者）"><a href="#batch-size-和-learning-rate-的关系（怎么平衡和调整二者）" class="headerlink" title="batch_size 和 learning rate 的关系（怎么平衡和调整二者）"></a>batch_size 和 learning rate 的关系（怎么平衡和调整二者）</h3><h3 id="解释过拟合和欠拟合，以及解决方法"><a href="#解释过拟合和欠拟合，以及解决方法" class="headerlink" title="解释过拟合和欠拟合，以及解决方法"></a>解释过拟合和欠拟合，以及解决方法</h3><h3 id="激活函数有哪些，各自区别"><a href="#激活函数有哪些，各自区别" class="headerlink" title="激活函数有哪些，各自区别"></a>激活函数有哪些，各自区别</h3><h3 id="损失函数有哪些"><a href="#损失函数有哪些" class="headerlink" title="损失函数有哪些"></a>损失函数有哪些</h3><h3 id="Sigmoid-和-ReLu-对比（各自优缺点）"><a href="#Sigmoid-和-ReLu-对比（各自优缺点）" class="headerlink" title="Sigmoid 和 ReLu 对比（各自优缺点）"></a>Sigmoid 和 ReLu 对比（各自优缺点）</h3><h3 id="为什么不用sigmoid而用relu？做出了哪些改进？"><a href="#为什么不用sigmoid而用relu？做出了哪些改进？" class="headerlink" title="为什么不用sigmoid而用relu？做出了哪些改进？"></a>为什么不用sigmoid而用relu？做出了哪些改进？</h3><h3 id="梯度消失和梯度爆炸的原因和解决方法"><a href="#梯度消失和梯度爆炸的原因和解决方法" class="headerlink" title="梯度消失和梯度爆炸的原因和解决方法"></a>梯度消失和梯度爆炸的原因和解决方法</h3><h3 id="Precision-和-Recall-的定义"><a href="#Precision-和-Recall-的定义" class="headerlink" title="Precision 和 Recall 的定义"></a>Precision 和 Recall 的定义</h3><h3 id="精确率高、召回率低是为什么"><a href="#精确率高、召回率低是为什么" class="headerlink" title="精确率高、召回率低是为什么"></a>精确率高、召回率低是为什么</h3><h3 id="SVM，线性回归和逻辑回归的原理及区别"><a href="#SVM，线性回归和逻辑回归的原理及区别" class="headerlink" title="SVM，线性回归和逻辑回归的原理及区别"></a>SVM，线性回归和逻辑回归的原理及区别</h3><h3 id="PCA原理，PCA和SVD的区别和联系"><a href="#PCA原理，PCA和SVD的区别和联系" class="headerlink" title="PCA原理，PCA和SVD的区别和联系"></a>PCA原理，PCA和SVD的区别和联系</h3><h3 id="正则化怎么选择，有哪些方式"><a href="#正则化怎么选择，有哪些方式" class="headerlink" title="正则化怎么选择，有哪些方式"></a>正则化怎么选择，有哪些方式</h3><h3 id="L1、L2范数，区别"><a href="#L1、L2范数，区别" class="headerlink" title="L1、L2范数，区别"></a>L1、L2范数，区别</h3><h3 id="boost、Adaboost"><a href="#boost、Adaboost" class="headerlink" title="boost、Adaboost"></a>boost、Adaboost</h3><h3 id="dropout和batch-normalization"><a href="#dropout和batch-normalization" class="headerlink" title="dropout和batch normalization"></a>dropout和batch normalization</h3><h3 id="讲一下决策树和随机森林"><a href="#讲一下决策树和随机森林" class="headerlink" title="讲一下决策树和随机森林"></a>讲一下决策树和随机森林</h3><h3 id="讲一下GBDT的细节，写出GBDT的目标函数。-GBDT和Adaboost的区别与联系"><a href="#讲一下GBDT的细节，写出GBDT的目标函数。-GBDT和Adaboost的区别与联系" class="headerlink" title="讲一下GBDT的细节，写出GBDT的目标函数。 GBDT和Adaboost的区别与联系"></a>讲一下GBDT的细节，写出GBDT的目标函数。 GBDT和Adaboost的区别与联系</h3><h3 id="偏差、方差"><a href="#偏差、方差" class="headerlink" title="偏差、方差"></a>偏差、方差</h3><h3 id="距离度量公式哪些，区别"><a href="#距离度量公式哪些，区别" class="headerlink" title="距离度量公式哪些，区别"></a>距离度量公式哪些，区别</h3><h3 id="多标签识别怎么做"><a href="#多标签识别怎么做" class="headerlink" title="多标签识别怎么做"></a>多标签识别怎么做</h3><h3 id="data-argumentation怎么处理的"><a href="#data-argumentation怎么处理的" class="headerlink" title="data argumentation怎么处理的"></a>data argumentation怎么处理的</h3><h3 id="数据不均衡怎么处理、只有少量带标签怎么处理"><a href="#数据不均衡怎么处理、只有少量带标签怎么处理" class="headerlink" title="数据不均衡怎么处理、只有少量带标签怎么处理"></a>数据不均衡怎么处理、只有少量带标签怎么处理</h3><h3 id="权重初始化方法都有哪些"><a href="#权重初始化方法都有哪些" class="headerlink" title="权重初始化方法都有哪些"></a>权重初始化方法都有哪些</h3><h3 id="权值衰减这个参数怎么设置"><a href="#权值衰减这个参数怎么设置" class="headerlink" title="权值衰减这个参数怎么设置"></a>权值衰减这个参数怎么设置</h3><h3 id="分类问题有哪些评价指标？每种的适用场景。"><a href="#分类问题有哪些评价指标？每种的适用场景。" class="headerlink" title="分类问题有哪些评价指标？每种的适用场景。"></a>分类问题有哪些评价指标？每种的适用场景。</h3><h3 id="无监督学习了解哪些"><a href="#无监督学习了解哪些" class="headerlink" title="无监督学习了解哪些"></a>无监督学习了解哪些</h3><h2 id="图像处理Opencv"><a href="#图像处理Opencv" class="headerlink" title="图像处理Opencv"></a>图像处理Opencv</h2><h3 id="边缘检测算子有哪些"><a href="#边缘检测算子有哪些" class="headerlink" title="边缘检测算子有哪些"></a>边缘检测算子有哪些</h3><h3 id="霍夫变换"><a href="#霍夫变换" class="headerlink" title="霍夫变换"></a>霍夫变换</h3><h3 id="直方图是什么"><a href="#直方图是什么" class="headerlink" title="直方图是什么"></a>直方图是什么</h3><h3 id="canny算子是怎么做的"><a href="#canny算子是怎么做的" class="headerlink" title="canny算子是怎么做的"></a>canny算子是怎么做的</h3><h3 id="图像的特征提取有哪些算法，适用范围、优缺点"><a href="#图像的特征提取有哪些算法，适用范围、优缺点" class="headerlink" title="图像的特征提取有哪些算法，适用范围、优缺点"></a>图像的特征提取有哪些算法，适用范围、优缺点</h3>
      
    </div>

	<div>
      
        


      
	</div>
	
	<div>
    
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">------ 本文结束------</div>
    
</div>


    
    </div>
	
    <div>
      
        
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/images/wechat-qcode.jpg" alt="bluesliuf wechat" style="width: 200px; max-width: 100%;">
    <div>坚持技术分享，欢迎大家扫码交流！</div>
</div>


      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>本文作者：</strong>
      bluesliuf
    </li>
    <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/" title="计算机视觉常见问题（含解答）">https://liufan.vip/深度学习/2019-4-18-计算机视觉常见问题/</a>
    </li>
    <li class="post-copyright-license">
      <strong>版权声明： </strong>
      本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
    </li>
  </ul>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/machine-learning/" rel="tag"><i class="fa fa-tag"></i> machine learning</a>
          
            <a href="/tags/deep-learning/" rel="tag"><i class="fa fa-tag"></i> deep learning</a>
          
            <a href="/tags/interview-question/" rel="tag"><i class="fa fa-tag"></i> interview question</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/深度学习/2019-4-18-CNN发展史/" rel="next" title="CNN网络架构演进：从LeNet到DenseNet">
                <i class="fa fa-chevron-left"></i> CNN网络架构演进：从LeNet到DenseNet
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/项目实战/2019-4-25-FaceNet在FPGA等硬件平台上的实现/" rel="prev" title="FaceNet在FPGA等硬件平台上的实现">
                FaceNet在FPGA等硬件平台上的实现 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC80MjM0NS8xODg5Mg=="></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="bluesliuf">
          <p class="site-author-name" itemprop="name">bluesliuf</p>
           
              <p class="site-description motion-element" itemprop="description">From Zero to Hero</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">54</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://blog.csdn.net/bluesliuf" target="_blank" title="CSDN">
                  
                    <i class="fa fa-fw fa-copyright"></i>
                  
                  CSDN
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://github.com/bluesliuf" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:bluesliuf@163.com" target="_blank" title="E-Mail">
                  
                    <i class="fa fa-fw fa-envelope"></i>
                  
                  E-Mail
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.instagram.com/bluesliuf/" target="_blank" title="INS">
                  
                    <i class="fa fa-fw fa-instagram"></i>
                  
                  INS
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN"><span class="nav-number">1.</span> <span class="nav-text">CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN在图像上表现好的原因"><span class="nav-number">1.1.</span> <span class="nav-text">CNN在图像上表现好的原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参数和计算量的计算"><span class="nav-number">1.2.</span> <span class="nav-text">参数和计算量的计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#调试、修改模型的经验"><span class="nav-number">1.3.</span> <span class="nav-text">调试、修改模型的经验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Inception-v1-v4区别、改进"><span class="nav-number">1.4.</span> <span class="nav-text">简述 Inception v1-v4区别、改进</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#V1"><span class="nav-number">1.4.1.</span> <span class="nav-text">V1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#V2"><span class="nav-number">1.4.2.</span> <span class="nav-text">V2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#V3"><span class="nav-number">1.4.3.</span> <span class="nav-text">V3</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#V4"><span class="nav-number">1.4.4.</span> <span class="nav-text">V4</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Inception-v1中的inception结构怎么设计的"><span class="nav-number">1.5.</span> <span class="nav-text">Inception v1中的inception结构怎么设计的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么使用1x1卷积核"><span class="nav-number">1.6.</span> <span class="nav-text">为什么使用1x1卷积核</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-CNN-的演变"><span class="nav-number">1.7.</span> <span class="nav-text">简述 CNN 的演变</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#讲一下CNN，每个层，及作用"><span class="nav-number">1.8.</span> <span class="nav-text">讲一下CNN，每个层，及作用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pooling层怎么反向传播"><span class="nav-number">1.9.</span> <span class="nav-text">Pooling层怎么反向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解释-ResNet-流行的原因"><span class="nav-number">1.10.</span> <span class="nav-text">解释 ResNet 流行的原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Resnet第二个版本做了哪些改进"><span class="nav-number">1.11.</span> <span class="nav-text">Resnet第二个版本做了哪些改进</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mobileNet、shuffleNet知道吗？"><span class="nav-number">1.12.</span> <span class="nav-text">mobileNet、shuffleNet知道吗？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#讲一下pooling的作用，-为什么max-pooling要更常用？哪些情况下，average-pooling比max-pooling更合适？"><span class="nav-number">1.13.</span> <span class="nav-text">讲一下pooling的作用， 为什么max pooling要更常用？哪些情况下，average pooling比max pooling更合适？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#哪些领域（数据集）不能使用深度学习？"><span class="nav-number">1.14.</span> <span class="nav-text">哪些领域（数据集）不能使用深度学习？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#细粒度分类"><span class="nav-number">1.15.</span> <span class="nav-text">细粒度分类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LSTM-amp-RNN"><span class="nav-number">2.</span> <span class="nav-text">LSTM&amp;RNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解释LSTM结构（相对于RNN）的好处"><span class="nav-number">2.1.</span> <span class="nav-text">解释LSTM结构（相对于RNN）的好处</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RNN的梯度消失原因和解决办法"><span class="nav-number">2.2.</span> <span class="nav-text">RNN的梯度消失原因和解决办法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Object-Detection"><span class="nav-number">3.</span> <span class="nav-text">Object Detection</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Unet的介绍"><span class="nav-number">3.1.</span> <span class="nav-text">Unet的介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FCN和Unet的区别"><span class="nav-number">3.2.</span> <span class="nav-text">FCN和Unet的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RCNN系列的算法流程和区别"><span class="nav-number">3.3.</span> <span class="nav-text">RCNN系列的算法流程和区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fast-RCNN中-bbox-回归的损失函数什么"><span class="nav-number">3.4.</span> <span class="nav-text">Fast RCNN中 bbox 回归的损失函数什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解释-ROI-Pooling-和-ROI-Align"><span class="nav-number">3.5.</span> <span class="nav-text">解释 ROI Pooling 和 ROI Align</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mask-RCNN中-mask-branch-如何接入-Faster-RCNN中"><span class="nav-number">3.6.</span> <span class="nav-text">Mask RCNN中 mask branch 如何接入 Faster RCNN中</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解释-FPN"><span class="nav-number">3.7.</span> <span class="nav-text">解释 FPN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解释-ROI-Align"><span class="nav-number">3.8.</span> <span class="nav-text">解释 ROI Align</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-YOLO-和-SSD"><span class="nav-number">3.9.</span> <span class="nav-text">简述 YOLO 和 SSD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Hough-直线检测、Sobel-边缘检测算法流程"><span class="nav-number">3.10.</span> <span class="nav-text">简述 Hough 直线检测、Sobel 边缘检测算法流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mask-RCNN中的anchors如何判定为正负样本"><span class="nav-number">3.11.</span> <span class="nav-text">Mask RCNN中的anchors如何判定为正负样本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-NMS-算法流程"><span class="nav-number">3.12.</span> <span class="nav-text">简述 NMS 算法流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#attention起源是用在哪里？pixel还是frame，是soft还是hard"><span class="nav-number">3.13.</span> <span class="nav-text">attention起源是用在哪里？pixel还是frame，是soft还是hard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#anchor的正负样本比是多少"><span class="nav-number">3.14.</span> <span class="nav-text">anchor的正负样本比是多少</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#算法和激活函数等"><span class="nav-number">4.</span> <span class="nav-text">算法和激活函数等</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#BN的原理和作用"><span class="nav-number">4.1.</span> <span class="nav-text">BN的原理和作用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BN-的作用和缺陷，以及针对batch-size小的情况的改进（GN）"><span class="nav-number">4.2.</span> <span class="nav-text">BN 的作用和缺陷，以及针对batch_size小的情况的改进（GN）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BN层，先加BN还是激活，有什么区别"><span class="nav-number">4.3.</span> <span class="nav-text">BN层，先加BN还是激活，有什么区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#手推BP"><span class="nav-number">4.4.</span> <span class="nav-text">手推BP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化算法举例和他们的区别（SGD、SGDM、RMSprop、Adam）"><span class="nav-number">4.5.</span> <span class="nav-text">优化算法举例和他们的区别（SGD、SGDM、RMSprop、Adam）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机梯度下降和梯度下降"><span class="nav-number">4.6.</span> <span class="nav-text">随机梯度下降和梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练不收敛的原因有哪些"><span class="nav-number">4.7.</span> <span class="nav-text">训练不收敛的原因有哪些</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-SVM-流程、核函数寻参及常见的核函数举例"><span class="nav-number">4.8.</span> <span class="nav-text">简述 SVM 流程、核函数寻参及常见的核函数举例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#batch-size-和-learning-rate-的关系（怎么平衡和调整二者）"><span class="nav-number">4.9.</span> <span class="nav-text">batch_size 和 learning rate 的关系（怎么平衡和调整二者）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解释过拟合和欠拟合，以及解决方法"><span class="nav-number">4.10.</span> <span class="nav-text">解释过拟合和欠拟合，以及解决方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#激活函数有哪些，各自区别"><span class="nav-number">4.11.</span> <span class="nav-text">激活函数有哪些，各自区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数有哪些"><span class="nav-number">4.12.</span> <span class="nav-text">损失函数有哪些</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid-和-ReLu-对比（各自优缺点）"><span class="nav-number">4.13.</span> <span class="nav-text">Sigmoid 和 ReLu 对比（各自优缺点）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么不用sigmoid而用relu？做出了哪些改进？"><span class="nav-number">4.14.</span> <span class="nav-text">为什么不用sigmoid而用relu？做出了哪些改进？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度消失和梯度爆炸的原因和解决方法"><span class="nav-number">4.15.</span> <span class="nav-text">梯度消失和梯度爆炸的原因和解决方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Precision-和-Recall-的定义"><span class="nav-number">4.16.</span> <span class="nav-text">Precision 和 Recall 的定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#精确率高、召回率低是为什么"><span class="nav-number">4.17.</span> <span class="nav-text">精确率高、召回率低是为什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVM，线性回归和逻辑回归的原理及区别"><span class="nav-number">4.18.</span> <span class="nav-text">SVM，线性回归和逻辑回归的原理及区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PCA原理，PCA和SVD的区别和联系"><span class="nav-number">4.19.</span> <span class="nav-text">PCA原理，PCA和SVD的区别和联系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化怎么选择，有哪些方式"><span class="nav-number">4.20.</span> <span class="nav-text">正则化怎么选择，有哪些方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L1、L2范数，区别"><span class="nav-number">4.21.</span> <span class="nav-text">L1、L2范数，区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#boost、Adaboost"><span class="nav-number">4.22.</span> <span class="nav-text">boost、Adaboost</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dropout和batch-normalization"><span class="nav-number">4.23.</span> <span class="nav-text">dropout和batch normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#讲一下决策树和随机森林"><span class="nav-number">4.24.</span> <span class="nav-text">讲一下决策树和随机森林</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#讲一下GBDT的细节，写出GBDT的目标函数。-GBDT和Adaboost的区别与联系"><span class="nav-number">4.25.</span> <span class="nav-text">讲一下GBDT的细节，写出GBDT的目标函数。 GBDT和Adaboost的区别与联系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#偏差、方差"><span class="nav-number">4.26.</span> <span class="nav-text">偏差、方差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#距离度量公式哪些，区别"><span class="nav-number">4.27.</span> <span class="nav-text">距离度量公式哪些，区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多标签识别怎么做"><span class="nav-number">4.28.</span> <span class="nav-text">多标签识别怎么做</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#data-argumentation怎么处理的"><span class="nav-number">4.29.</span> <span class="nav-text">data argumentation怎么处理的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据不均衡怎么处理、只有少量带标签怎么处理"><span class="nav-number">4.30.</span> <span class="nav-text">数据不均衡怎么处理、只有少量带标签怎么处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#权重初始化方法都有哪些"><span class="nav-number">4.31.</span> <span class="nav-text">权重初始化方法都有哪些</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#权值衰减这个参数怎么设置"><span class="nav-number">4.32.</span> <span class="nav-text">权值衰减这个参数怎么设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分类问题有哪些评价指标？每种的适用场景。"><span class="nav-number">4.33.</span> <span class="nav-text">分类问题有哪些评价指标？每种的适用场景。</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#无监督学习了解哪些"><span class="nav-number">4.34.</span> <span class="nav-text">无监督学习了解哪些</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像处理Opencv"><span class="nav-number">5.</span> <span class="nav-text">图像处理Opencv</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#边缘检测算子有哪些"><span class="nav-number">5.1.</span> <span class="nav-text">边缘检测算子有哪些</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#霍夫变换"><span class="nav-number">5.2.</span> <span class="nav-text">霍夫变换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#直方图是什么"><span class="nav-number">5.3.</span> <span class="nav-text">直方图是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#canny算子是怎么做的"><span class="nav-number">5.4.</span> <span class="nav-text">canny算子是怎么做的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图像的特征提取有哪些算法，适用范围、优缺点"><span class="nav-number">5.5.</span> <span class="nav-text">图像的特征提取有哪些算法，适用范围、优缺点</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluesliuf</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  





  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  
  <!-- 代码块复制功能 -->
  <script type="text/javascript" src="/js/src/clipboard.min.js"></script>  
  <script type="text/javascript" src="/js/src/clipboard-use.js"></script>
</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>